{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BocsCxFfg8mO",
        "outputId": "fe4a26cf-2b8a-4911-b1cc-8475c44bcb75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6234\n",
            "Precision: 0.6171\n",
            "Recall: 0.6234\n",
            "F1-score: 0.6150\n",
            "Weather\n",
            "19    2106\n",
            "23    2069\n",
            "1     1728\n",
            "0     1326\n",
            "35     390\n",
            "24     306\n",
            "25     188\n",
            "7      150\n",
            "28     116\n",
            "3       80\n",
            "37      60\n",
            "2       41\n",
            "40      37\n",
            "39      19\n",
            "31      18\n",
            "47      16\n",
            "18      16\n",
            "6       15\n",
            "13      14\n",
            "11      11\n",
            "8        7\n",
            "9        6\n",
            "42       6\n",
            "41       5\n",
            "14       4\n",
            "12       4\n",
            "21       4\n",
            "34       4\n",
            "38       4\n",
            "29       3\n",
            "10       3\n",
            "46       3\n",
            "48       3\n",
            "15       2\n",
            "5        2\n",
            "27       2\n",
            "43       2\n",
            "22       2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# 1. Load and process data\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/Project 1 - Weather Dataset.csv')\n",
        "# check rows and columns\n",
        "df\n",
        "# Check for missing values\n",
        "# print(df.isnull().sum())\n",
        "\n",
        "# 2. Feature Engineering\n",
        "# Convert Date/Time to datetime format\n",
        "df['Date/Time'] = pd.to_datetime(df['Date/Time'])\n",
        "# Extract temporal features\n",
        "df['hour'] = df['Date/Time'].dt.hour\n",
        "df['day_of_week'] = df['Date/Time'].dt.weekday\n",
        "df['month'] = df['Date/Time'].dt.month\n",
        "# Drop the original Date/Time column\n",
        "df.drop('Date/Time', axis=1, inplace=True)\n",
        "# The Weather column is the target variable, which is categorical\n",
        "#to encode this column into numeric labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Label encode the target variable (Weather)\n",
        "le = LabelEncoder()\n",
        "df['Weather'] = le.fit_transform(df['Weather'])\n",
        "#df\n",
        "\n",
        "# 3. Feature scaling\n",
        "# as some features are in different units scale the data using standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Select numerical columns for scaling\n",
        "numerical_features = ['Temp_C', 'Dew Point Temp_C', 'Rel Hum_%', 'Wind Speed_km/h', 'Visibility_km', 'Press_kPa', 'hour', 'day_of_week', 'month']\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Remove classes with fewer than 2 samples\n",
        "rare_classes = y.value_counts()[y.value_counts() < 2].index\n",
        "df = df[~df['Weather'].isin(rare_classes)]\n",
        "\n",
        "# 4. Split the data\n",
        "# split the data features to x and target to Y and further split into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Features (X) and target (y)\n",
        "X = df.drop('Weather', axis=1)\n",
        "y = df['Weather']\n",
        "# Split data into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#5. train the model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "# rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "\n",
        "# Train the model\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Check distribution of the target variable\n",
        "print(y.value_counts())\n"
      ]
    }
  ]
}